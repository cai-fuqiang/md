# 测试统计 - 03-07 统计

## 46 node-1
|复现时间|复现时长/min|该时间段最高负载|
|--|--|--|
|01:31-01:32|1|100+|
|02:15-02:16|1|200+|
|02:31-02:33|2|250+|
|02:47-03-48|1|300+|
|03:03-03-05|2|300+|
|03:19-03-30 |11|2000+|

* 当日总次数: 6
* 当日总时长: 18 min

## node-2:
|复现时间|复现时长/min|该时间段最高负载|
|--|--|--|
|03:29-03-35|6|1000+|
|03:51-03-53|2|550+|
|04:29-04:32|3|1200+|
|05:46-05:49|3|800+|
|06:28-06:29|1|200+|
|06:30-06-32|2|250+|
|07:53-07:57|4|1000+|



* 当日总次数:7
* 当日总时长:21 min
## node-3:
无

# 51环境
## node-1
无
## node-2
无
## node-3

|复现时间|复现时长/min|该时间段最高负载|
|--|--|--|
|23:20-23:23|3|700+|
|00:03-00:05|2|400+|
|00:34-00:38|4|1400+|
|02:53-02:57|4|1600+|
|07:59-08:01|2|400+|
|08:44-08:47|3|600+|

* 当日总次数: 6
* 当日总时长: 18 min

# 51环境调整 - 03-07 17:55
将drop_cache.sh定时任务加上


# 测试统计 - 03-08 统计

## node-1
|复现时间|复现时长/min|该时间段最高负载|
|--|--|--|
|05:09-05:11|3|450+|

# node-2
|复现时间|复现时长/min|该时间段最高负载|
|--|--|--|
|08:37-08:41|4|1350+|

# node-3
|复现时间|复现时长/min|该时间段最高负载|
|--|--|--|
|23:07-23:10|3|600+|
|00:08-12:12|4|1150+|
|08:20-08:23|3|850+|

# 46环境调整  - 03-07 21:57
替换kernel (增加trace event code).
在高负载时统计0-16核的调度event



# 测试统计 - 03 -11
## 51环境
### node-2
|复现时间|复现时长/min|该时间段最高负载|
|--|--|--|
|03-09 20:27-08:29|2|300+|
|03-09 22:00-10:02|2|350+|

## node-3
|复现时间|复现时长/min|该时间段最高负载|
|--|--|--|
|03-08 22:07-22:10|3|600+|
|03-09 14:41-15:42|1|200+|
|03-09 15:09-15:12|3|400+|
|03-09 16:19-16:22|3|500+|
|03-09 17:03-17:05|2|300+|
|03-09 19:08-19:09|1|200+|
|03-09 20:24-20:26|2|800+|
|03-09 22:05-22:08|3|600+|

## 46 环境
该环境自动化测试停止,未复现


# 46环境调整 - 03-11 20:49
替换kernel, 除去调度event(日志太乱)

# 49 环境调整 - 03-14 21:00
替换kernel, 优化`expand_one_shrinker_info`, 目前看起来良好


# 测试统计 - 03-18 21:14 -- 03-20 10:11
## 51 环境
### node-1
|复现时间|复现时长|该时间段最高负载|
|--|--|--|
|03-19 23:24:58 - 23:25:03|10s-|100+|
> NOTE
>
> 这个也不算复现, 持续时间太短

### node-2
无

### node-3
|复现时间|复现时长/min|该时间段最高负载|
|--|--|--|
|03-19 15:54:25-15:54:37|30s-|103|
|03-19 16:22:23-16:22:55|30s+|143|
|03-19 19:00:51-19:01:29|40s+|143|
|03-20 11:20:44-11:26:32|6m|430|


### 该环境其他信息
我们在该环境中发现有一定的系统负载:

```
top - 11:04:47 up 5 days, 8 min,  2 users,  load average: 33.93, 32.24, 29.02
Tasks: 4312 total,  17 running, 4292 sleeping,   0 stopped,   3 zombie
%Cpu0  : 17.6 us, 20.1 sy,  0.0 ni, 57.1 id,  0.0 wa,  0.0 hi,  5.2 si,  0.0 st
%Cpu1  : 18.6 us, 15.0 sy,  0.0 ni, 63.6 id,  0.4 wa,  0.0 hi,  2.5 si,  0.0 st
%Cpu2  : 17.1 us, 15.4 sy,  0.0 ni, 63.8 id,  0.3 wa,  0.0 hi,  3.4 si,  0.0 st
%Cpu3  : 20.0 us,  9.5 sy,  0.0 ni, 63.2 id,  0.4 wa,  0.0 hi,  7.0 si,  0.0 st
%Cpu4  : 22.3 us, 21.9 sy,  0.0 ni, 50.2 id,  0.0 wa,  0.0 hi,  5.6 si,  0.0 st
%Cpu5  : 21.2 us, 14.8 sy,  0.0 ni, 59.0 id,  0.7 wa,  0.0 hi,  4.2 si,  0.0 st
%Cpu6  : 20.6 us, 23.6 sy,  0.0 ni, 48.5 id,  0.3 wa,  0.0 hi,  7.0 si,  0.0 st
%Cpu7  : 14.3 us, 25.3 sy,  0.0 ni, 50.3 id,  0.3 wa,  0.0 hi,  9.7 si,  0.0 st
%Cpu8  : 22.4 us, 13.1 sy,  0.0 ni, 62.4 id,  1.0 wa,  0.0 hi,  1.0 si,  0.0 st
%Cpu9  : 15.9 us, 31.8 sy,  0.0 ni, 51.0 id,  0.3 wa,  0.0 hi,  1.0 si,  0.0 st
%Cpu10 : 21.6 us, 12.8 sy,  0.0 ni, 63.5 id,  1.4 wa,  0.0 hi,  0.7 si,  0.0 st
%Cpu11 : 15.8 us, 13.1 sy,  0.0 ni, 69.4 id,  1.0 wa,  0.0 hi,  0.7 si,  0.0 st
%Cpu12 : 19.4 us, 20.8 sy,  0.0 ni, 59.2 id,  0.0 wa,  0.0 hi,  0.7 si,  0.0 st
%Cpu13 : 27.4 us, 10.3 sy,  0.0 ni, 61.0 id,  0.7 wa,  0.0 hi,  0.7 si,  0.0 st
%Cpu14 : 13.1 us, 23.2 sy,  0.0 ni, 63.0 id,  0.3 wa,  0.0 hi,  0.3 si,  0.0 st
%Cpu15 : 18.4 us, 15.3 sy,  0.0 ni, 65.0 id,  0.7 wa,  0.0 hi,  0.7 si,  0.0 st
```

perf top 进行统计时, 发现在收包.
```
+   28.65%     0.01%  [kernel]                                    [k] el0_svc
+   28.53%     0.81%  [kernel]                                    [k] el0_svc_handler
+   24.81%     0.00%  libc-2.27.so                                [.] 0x0000ffff836204ec
+   24.81%     0.00%  libpthread-2.27.so                          [.] 0x0000ffff836b7088
+   24.81%     0.00%  beam.smp                                    [.] 0x0000aaaac3cbb780
+   21.35%     0.00%  [kernel]                                    [k] cpu_startup_entry
+   21.33%     0.16%  [kernel]                                    [k] do_idle
+   20.33%     0.00%  beam.smp                                    [.] 0x0000aaaac3a2f1e4
+   19.95%     3.59%  [kernel]                                    [k] __schedule
+   19.37%     0.00%  [kernel]                                    [k] secondary_start_kernel
+   19.21%     2.21%  [kernel]                                    [k] __softirqentry_text_start
+   16.90%     0.00%  beam.smp                                    [.] 0x0000aaaac3a37e64
+   16.16%    14.49%  [kernel]                                    [k] finish_task_switch
+   15.37%     0.00%  [kernel]                                    [k] gic_handle_irq
+   15.37%     0.00%  [kernel]                                    [k] irq_exit
+   15.37%     0.00%  [kernel]                                    [k] irq_exit_rcu
+   14.93%     0.00%  [kernel]                                    [k] __handle_domain_irq
+   14.42%     0.05%  [kernel]                                    [k] net_rx_action
+   14.33%     0.00%  [kernel]                                    [k] __napi_poll
+   12.77%     0.00%  [kernel]                                    [k] el1_irq
```

向彬彬, 继德请教, 发现该环境在做网络测试, 不知道该行为对高负载会不会有影响.

> NOTE
>
> 暂时的结论:
>
> 经这两天测试, 看起来高负载有所缓解. 因为目前的 es8_9 kernel 并没有合入优化`shrink_slab`性能
> 的patch. 需要进一步测试验证合入该patch后,高负载问题 会不会长时间不复现.

# 测试统计 - 03-20-10:11 - 03-21-10:48
## node-1
|复现时间|复现时长|该时间段最高负载|
|--|--|--|
|03-20 15:02-15:03|1m|111|
|03-20 16:18-16:32|14m|230|
|03-20 23:22-23:24|2m|163|

## node-2
|复现时间|复现时长|该时间段最高负载|
|--|--|--|
|03-20 16:16-16:31|15m|216|
|03-20 16:30-16-37|7m|183|

## node-3
|复现时间|复现时长|该时间段最高负载|
|--|--|--|
|03-19 13:01-13:02|1m|200|
|03-19 14:29-14:37|8m|217|
|03-19 16:19-16:23|4m|147|
|03-19 16:27-16:55|28m|240|
|03-19 17:01-17:06|5m|205|
|03-19 17:14-17:15|1m|115|
|03-19 17:37|30s|119|
|03-20 17:49-17:51|2m|218|
|03-20 18:23-18:24|2m|202|
|03-20 18:23-18:24|2m|202|
|03-20 18:43|30s-|104|
|03-20 18:58-19:06|8m|841|
|03-20 20:03-20:22|19m|330|
|03-20 20:36-20:37|1m|157|
|03-20 21:24-21:25|1m|206|
|03-20 21:39-21:41|3m|270|
|03-20 21:55-21:56|1m|108|
|03-20 22:28|1m|140|
|03-20 22:44|1m|155|
|03-20 23:21-23:23|2m|175|
|03-20 23:47-23:51|4m|700|

# 测试统计 - 03-22-10:42 ~ 03-25 - 14-00
因为该环境可能有其他负载,统计高负载没有什么意义, 我们主要看出现`nr_reclaim < 32` 的统计情况
```
[root@node-3 ~]# /root/wangfuqiang/code_bak/mm_vmscan_end /root/wangfuqiang/data/ftrace/bak/trace_2024-03-25-14-00-27.log |grep -v 'LOW \[   0\]'
[root@node-2 ~]# /root/wangfuqiang/code_bak/mm_vmscan_end /root/wangfuqiang/data/ftrace/bak/trace_2024-03-25-14-00-18.log |grep -v 'LOW \[   0\]'
cpu[ 15] second[616556] time[2024-03-22 14:12:09] average[  32] LOW [   1] ALL[   2]  RECLAIM NUM COUNT : [25](  1) [31](  1)
[root@node-1 wangfuqiang]# ./code_bak/mm_vmscan_end ./data/ftrace/bak/trace_2024-03-25-14-00-10.log |grep -v 'LOW \[   0\]'
cpu[  9] second[616663] time[2024-03-22 14:14:43] average[  41] LOW [   1] ALL[   3]  RECLAIM NUM COUNT : [21](  1) [31](  2)
cpu[  5] second[616665] time[2024-03-22 14:14:45] average[  30] LOW [   1] ALL[   4]  RECLAIM NUM COUNT : [ 0](  1) [31](  3)
cpu[ 10] second[616668] time[2024-03-22 14:14:48] average[  17] LOW [   1] ALL[   2]  RECLAIM NUM COUNT : [ 0](  1) [31](  1)
cpu[  9] second[616671] time[2024-03-22 14:14:51] average[  39] LOW [   1] ALL[   5]  RECLAIM NUM COUNT : [28](  1) [31](  4)
cpu[  3] second[616680] time[2024-03-22 14:15:00] average[  28] LOW [   1] ALL[   1]  RECLAIM NUM COUNT : [28](  1)
cpu[ 10] second[616681] time[2024-03-22 14:15:01] average[  33] LOW [   1] ALL[   3]  RECLAIM NUM COUNT : [28](  1) [31](  2)
cpu[  4] second[616684] time[2024-03-22 14:15:04] average[  24] LOW [   1] ALL[   3]  RECLAIM NUM COUNT : [ 0](  1) [31](  2)
cpu[  5] second[616688] time[2024-03-22 14:15:08] average[  33] LOW [   1] ALL[   5]  RECLAIM NUM COUNT : [16](  1) [31](  4)
cpu[ 11] second[616687] time[2024-03-22 14:15:07] average[  34] LOW [   1] ALL[   4]  RECLAIM NUM COUNT : [17](  1) [31](  3)
cpu[ 14] second[616690] time[2024-03-22 14:15:10] average[  31] LOW [   1] ALL[   1]  RECLAIM NUM COUNT : [31](  1)
cpu[  5] second[616693] time[2024-03-22 14:15:13] average[  38] LOW [   1] ALL[   3]  RECLAIM NUM COUNT : [14](  1) [31](  2)
cpu[  2] second[616695] time[2024-03-22 14:15:15] average[  42] LOW [   1] ALL[   4]  RECLAIM NUM COUNT : [20](  1) [31](  3)
cpu[  9] second[616699] time[2024-03-22 14:15:19] average[  48] LOW [   1] ALL[   4]  RECLAIM NUM COUNT : [23](  1) [31](  3)
cpu[ 13] second[616702] time[2024-03-22 14:15:22] average[  17] LOW [   1] ALL[   2]  RECLAIM NUM COUNT : [ 0](  1) [31](  1)
cpu[ 11] second[616704] time[2024-03-22 14:15:24] average[  32] LOW [   1] ALL[   5]  RECLAIM NUM COUNT : [19](  1) [31](  4)
cpu[ 11] second[616708] time[2024-03-22 14:15:28] average[  32] LOW [   1] ALL[   3]  RECLAIM NUM COUNT : [29](  1) [31](  2)
```
可以发现并不是很多, 主要在 node-1 中有, 但是在该时间段, 并没有高负载现象
```
02:14:00 PM         9     14905     26.30     23.82     20.43         1
02:14:02 PM        18     14922     25.31     23.65     20.39         1
02:14:04 PM        10     14919     25.31     23.65     20.39         1
02:14:06 PM        12     14898     24.49     23.51     20.36         0
02:14:08 PM         9     14900     24.49     23.51     20.36         0
02:14:10 PM         4     15158     24.49     23.51     20.36         0
02:14:12 PM        13     14882     23.73     23.37     20.34         0
02:14:14 PM        19     14912     23.73     23.37     20.34         1
02:14:16 PM        10     14883     22.95     23.21     20.30         1
02:14:18 PM        16     14902     22.95     23.21     20.30         0
02:14:20 PM        11     14871     22.95     23.21     20.30         3
02:14:22 PM         3     14859     22.95     23.21     20.32         0
02:14:24 PM        14     14870     22.95     23.21     20.32         0
02:14:26 PM         8     14864     22.00     23.01     20.27         0
02:14:28 PM       109     14864     22.00     23.01     20.27         0
02:14:30 PM        24     14879     22.00     23.01     20.27         0
02:14:32 PM        10     14871     23.12     23.22     20.35         0
02:14:34 PM        13     14873     23.12     23.22     20.35         0
02:14:36 PM        11     14874     22.31     23.05     20.31         0
02:14:38 PM        11     14870     22.31     23.05     20.31         0
02:14:40 PM        16     15133     22.31     23.05     20.31         0
02:14:42 PM         8     14859     21.00     22.77     20.23         0
02:14:44 PM         8     14858     21.00     22.77     20.23         1
02:14:46 PM        14     14844     21.08     22.75     20.24         0
02:14:48 PM         9     14845     21.08     22.75     20.24         0
02:14:50 PM        20     14851     21.08     22.75     20.24         2
02:14:52 PM         9     14859     20.19     22.54     20.19         0
02:14:54 PM         6     14882     20.19     22.54     20.19         0
02:14:56 PM        13     14878     20.42     22.55     20.20         0
02:14:58 PM         8     14867     20.42     22.55     20.20         1
```
这段时间的内存使用量还有很多
```
Fri Mar 22 14:14:54 CST 2024
 14:14:54 up 7 days,  3:17,  0 users,  load average: 20.19, 22.54, 20.19
LIMIT 53688074240
USAGE 43237900288

total_inactive_anon 31468945408 30011 M
total_active_anon 99352576 94 M
total_inactive_file 5652742144 5390 M
total_active_file 5986320384 5709 M
LEFT   10450173952 LEFT_m   9966 M
ANON_m 30105 M
FILE_m 11099 M

Fri Mar 22 14:14:57 CST 2024
 14:14:57 up 7 days,  3:17,  0 users,  load average: 20.42, 22.55, 20.20
LIMIT 53688074240
USAGE 43243405312

total_inactive_anon 31481462784 30023 M
total_active_anon 99024896 94 M
total_inactive_file 6500646912 6199 M
total_active_file 5130158080 4892 M
LEFT   10444668928 LEFT_m   9960 M
ANON_m 30117 M
FILE_m 11091 M

Fri Mar 22 14:15:00 CST 2024
 14:15:00 up 7 days,  3:18,  0 users,  load average: 19.90, 22.41, 20.17
LIMIT 53688074240
USAGE 43267784704

total_inactive_anon 31508987904 30049 M
total_active_anon 99024896 94 M
total_inactive_file 8023900160 7652 M
total_active_file 3601727488 3434 M
LEFT   10420289536 LEFT_m   9937 M
ANON_m 30143 M
FILE_m 11086 M

Fri Mar 22 14:15:03 CST 2024
 14:15:03 up 7 days,  3:18,  0 users,  load average: 19.90, 22.41, 20.17
LIMIT 53688074240
USAGE 43297210368

total_inactive_anon 31527272448 30066 M
total_active_anon 99090432 94 M
total_inactive_file 6499860480 6198 M
total_active_file 5137235968 4899 M
LEFT   10390863872 LEFT_m   9909 M
ANON_m 30160 M
FILE_m 11097 M
```

个人怀疑, 不是 `k8s`顶层的mem cgroup 的内存回收.

查看 ftrace log , 找到触发 `nr_reclaim < 32` 的进程:
> NOTE
> 
> 以
> ```
> cpu[  9] second[616663] time[2024-03-22 14:14:43] average[  41] LOW [   1] ALL[   3]  RECLAIM NUM COUNT : [21](  1) [31](  2)
> ```
> 为例

```
cinder-volume-39312 [009] .N.. 616663.862806: mm_vmscan_memcg_reclaim_end: nr_reclaimed=21
```

查看该进程所在的 cgroup
```
[root@node-1 ~]# ps aux |grep cinder-volume
root     20470  0.0  0.0 216640  1536 pts/21   S+   14:33   0:00 grep --color=auto cinder-volume
42407    55128  1.3  0.0 402304 142016 ?       Ss   Mar22  51:36 /usr/bin/python3 /usr/local/bin/cinder-volume --config-file /etc/cinder/cinder.conf --config-file /etc/cinder/conf/backends.conf --config-file /etc/cinder/conf/image_volume_cache.conf
42407    63350  4.9  0.0 6740992 244416 ?      Sl   Mar22 186:34 /usr/bin/python3 /usr/local/bin/cinder-volume --config-file /etc/cinder/cinder.conf --config-file /etc/cinder/conf/backends.conf --config-file /etc/cinder/conf/image_volume_cache.conf
42407    63934  0.1  0.0 411008 129088 ?       S    Mar22   5:21 /usr/bin/python3 /usr/local/bin/cinder-volume --config-file /etc/cinder/cinder.conf --config-file /etc/cinder/conf/backends.conf --config-file /etc/cinder/conf/image_volume_cache.conf
[root@node-1 ~]# cat /proc/55128/cgroup  |grep mem
6:memory:/kubepods/burstable/pod84bda5f9-e2e5-46b6-b9f5-5780b8c0b2b3/e6dba6fc809a3145683d95889c3c00b0ecb2788f41a579822d7ef900dca1b9dd
```
查看其内存限制
```
[root@node-1 ~]# cat /sys/fs/cgroup/memory//kubepods/burstable/pod84bda5f9-e2e5-46b6-b9f5-5780b8c0b2b3/e6dba6fc809a3145683d95889c3c00b0ecb2788f41a579822d7ef900dca1b9dd/memory.limit_in_bytes
4 294 967 296
```
可以看到为4G.

所以个人认为目前并没有出现极端情况.
